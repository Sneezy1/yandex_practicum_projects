{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install transformers\n",
    "!pip install lightgbm\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные и посмотрим на них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим примерно 160000 записей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классы несбалансированы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку вычисления могут идти очень долго, возьмем примерно по 1% записей каждого из классов (пробовал брать 20000 записей, примерно время было 56 часов.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45045</th>\n",
       "      <td>\"\\nI was talking about them running any check ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27198</th>\n",
       "      <td>White Trash\\nFuck off you white piece of trash...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16664</th>\n",
       "      <td>eat shit get rid of goofs you queers.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8158</th>\n",
       "      <td>DUMB ASSES\\nIt's was my sockpuppet...joe hazet...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142212</th>\n",
       "      <td>Are all professors of rhetoric pompous, self-c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98074</th>\n",
       "      <td>Images \\n\\nYou have been uploading copyrighted...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157626</th>\n",
       "      <td>\"\\n\\n Quote \\n\\nA fairly minor point but do we...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151400</th>\n",
       "      <td>'s official site and Hendrick's driver page fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124061</th>\n",
       "      <td>Yiddish: Asyva (pronunciation) \\n\\n Asyva (in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18755</th>\n",
       "      <td>I concur Milkncookie. I intended to move the p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1570 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "45045   \"\\nI was talking about them running any check ...      1\n",
       "27198   White Trash\\nFuck off you white piece of trash...      1\n",
       "16664               eat shit get rid of goofs you queers.      1\n",
       "8158    DUMB ASSES\\nIt's was my sockpuppet...joe hazet...      1\n",
       "142212  Are all professors of rhetoric pompous, self-c...      1\n",
       "...                                                   ...    ...\n",
       "98074   Images \\n\\nYou have been uploading copyrighted...      0\n",
       "157626  \"\\n\\n Quote \\n\\nA fairly minor point but do we...      0\n",
       "151400  's official site and Hendrick's driver page fo...      0\n",
       "124061  Yiddish: Asyva (pronunciation) \\n\\n Asyva (in ...      0\n",
       "18755   I concur Milkncookie. I intended to move the p...      0\n",
       "\n",
       "[1570 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_data = data.query('toxic == 1').sample(170, random_state=42)\n",
    "neg_data = data.query('toxic == 0').sample(1400, random_state=42)\n",
    "data_sample = pd.concat([pos_data, neg_data])\n",
    "data_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на пример текста из датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"DUMB ASSES\\nIt's was my sockpuppet...joe hazeton... you guys are out of control..... i am making a folder which will be submited to higher athority, one above the GOD KING JIMBO.... I WOULD STRONGLY SUGGEST YOU FIGURE IT OUT FAST...I DON'T MR BH will LIKE HIS FULL NAME PUBLISH ON WIKIPEDIA AS A NON-NOTABLE WITh charges of slander and libel forthwith...  JOEHAZELTON...PS I DON't KNOW BRYAN OR DINO\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample.loc[:, 'text'].reset_index(drop=True)[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Избавимся от цифр, знаков пунктуации и других ненужных символов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    new_words = tokenizer.tokenize(text)\n",
    "    result  = ' '.join(new_words)\n",
    "    result = re.sub(r'[0-9]+', '', result)\n",
    "    result = result.strip()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample['text'] = data_sample['text'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на результаты обработки на примере того же текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DUMB ASSES It s was my sockpuppet joe hazeton you guys are out of control i am making a folder which will be submited to higher athority one above the GOD KING JIMBO I WOULD STRONGLY SUGGEST YOU FIGURE IT OUT FAST I DON T MR BH will LIKE HIS FULL NAME PUBLISH ON WIKIPEDIA AS A NON NOTABLE WITh charges of slander and libel forthwith JOEHAZELTON PS I DON t KNOW BRYAN OR DINO'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample.loc[:, 'text'].reset_index(drop=True)[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем встроенный в BERT токенизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizer(vocab_file='vocab.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посколько мы используем уже обученную модель и мы не можем её переобучить, мы должны выбрать те записи, в которых число токенов не превышает 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = data_sample['text'].apply(lambda x: tokenizer.encode(x, \n",
    "                                                        truncation=True, \n",
    "                                                        max_length=max_seq_length, \n",
    "                                                        add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = pad_sequence([torch.as_tensor(seq) for seq in tokenized], batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = np.array(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Укажем файл конфига и обученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "config = transformers.BertConfig.from_pretrained('bert_config.json')\n",
    "model = transformers.BertModel.from_pretrained('bert-base-uncased', config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем эмбеддинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f8ba417f954a4383ba76797c5d959b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/785 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "объединим признаки в один массив"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на обучающую и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, y_train, y_test = train_test_split(features, data_sample['toxic'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном шаге обучим три различных модели и посмотрим значение метрики F<sub>1</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "lr_score = cross_val_score(model, features, data_sample['toxic'], cv=5, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение метрики F1 для логистической регрессии: 0.76\n"
     ]
    }
   ],
   "source": [
    "print(f'Значение метрики F1 для логистической регрессии: {max(lr_score):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rf = [\n",
    "    {\n",
    "        'max_depth': [i for i in range(1, 10, 2)],\n",
    "        'min_samples_split': [i for i in range(2, 10, 2)]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('classifier',\n",
       "                 GridSearchCV(cv=5,\n",
       "                              estimator=RandomForestClassifier(random_state=42),\n",
       "                              param_grid=[{'max_depth': [1, 3, 5, 7, 9],\n",
       "                                           'min_samples_split': [2, 4, 6, 8]}],\n",
       "                              scoring='f1'))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = GridSearchCV(RandomForestClassifier(random_state=42, n_estimators=100), param_grid_rf, scoring='f1', cv=5)\n",
    "rf_pipeline = Pipeline(steps=[('classifier', rf_model)])\n",
    "rf_pipeline.fit(features_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение метрики F1 для случайного леса: 0.20408163265306123\n"
     ]
    }
   ],
   "source": [
    "rf_pred = rf_pipeline.predict(features_test)\n",
    "rf_model_score = f1_score(y_test, rf_pred)\n",
    "print(f'Значение метрики F1 для случайного леса: {rf_model_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lgbm = [\n",
    "    {\n",
    "        'max_depth': [i for i in range(1, 6, 2)],\n",
    "        'learning_rate': [0.1, 0.01, 0.2]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('classifier',\n",
       "                 GridSearchCV(cv=5, estimator=LGBMClassifier(random_state=42),\n",
       "                              param_grid=[{'learning_rate': [0.1, 0.01, 0.2],\n",
       "                                           'max_depth': [1, 3, 5]}],\n",
       "                              scoring='f1'))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_model = GridSearchCV(LGBMClassifier(random_state=42), param_grid_lgbm, scoring='f1', cv=5)\n",
    "lgbm_pipeline = Pipeline(steps=[('classifier', lgbm_model)])\n",
    "lgbm_pipeline.fit(features_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение метрики F1 для модели из lightGBM: 0.47457627118644075\n"
     ]
    }
   ],
   "source": [
    "lgbm_pred = lgbm_pipeline.predict(features_test)\n",
    "lgbm_model_score = f1_score(y_test, lgbm_pred)\n",
    "print(f'Значение метрики F1 для модели из lightGBM: {lgbm_model_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если использовать больше данных из датасета, возможно мы получим немного другие результаты на других моделях, но с текущей выборкой логистическая регрессия обучается быстрее всех и даёт лучший результат.Поэтому выберем модель логистической регрессии.  \n",
    "Значение метрики F<sub>1</sub>: 0.76\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 970,
    "start_time": "2022-02-12T19:43:16.237Z"
   },
   {
    "duration": 3,
    "start_time": "2022-02-12T19:43:21.950Z"
   },
   {
    "duration": 2641,
    "start_time": "2022-02-12T19:43:41.731Z"
   },
   {
    "duration": 2674,
    "start_time": "2022-02-12T19:44:02.320Z"
   },
   {
    "duration": 2,
    "start_time": "2022-02-12T19:44:05.739Z"
   },
   {
    "duration": 2317,
    "start_time": "2022-02-12T19:44:06.123Z"
   },
   {
    "duration": 2700,
    "start_time": "2022-02-12T19:44:32.272Z"
   },
   {
    "duration": 536,
    "start_time": "2022-02-12T19:44:42.683Z"
   },
   {
    "duration": 23,
    "start_time": "2022-02-12T19:44:48.903Z"
   },
   {
    "duration": 19,
    "start_time": "2022-02-12T19:44:55.049Z"
   },
   {
    "duration": 10,
    "start_time": "2022-02-12T19:45:01.243Z"
   },
   {
    "duration": 7,
    "start_time": "2022-02-12T19:47:57.475Z"
   },
   {
    "duration": 8,
    "start_time": "2022-02-12T19:48:00.586Z"
   },
   {
    "duration": 5947,
    "start_time": "2022-02-12T19:48:14.683Z"
   },
   {
    "duration": 324,
    "start_time": "2022-02-12T19:48:22.280Z"
   },
   {
    "duration": 339,
    "start_time": "2022-02-12T19:48:32.783Z"
   },
   {
    "duration": 359,
    "start_time": "2022-02-12T19:48:35.640Z"
   },
   {
    "duration": 4,
    "start_time": "2022-02-12T19:48:38.791Z"
   },
   {
    "duration": 3,
    "start_time": "2022-02-12T19:50:15.518Z"
   },
   {
    "duration": 4,
    "start_time": "2022-02-12T19:50:32.950Z"
   },
   {
    "duration": 4,
    "start_time": "2022-02-12T19:50:35.928Z"
   },
   {
    "duration": 3,
    "start_time": "2022-02-12T19:50:43.478Z"
   },
   {
    "duration": 177,
    "start_time": "2022-02-12T20:07:42.724Z"
   },
   {
    "duration": 126,
    "start_time": "2022-02-12T20:09:24.422Z"
   },
   {
    "duration": 3,
    "start_time": "2022-02-12T20:09:27.538Z"
   },
   {
    "duration": 87032,
    "start_time": "2022-02-12T20:10:13.618Z"
   },
   {
    "duration": 121,
    "start_time": "2022-02-12T20:11:40.531Z"
   },
   {
    "duration": 7,
    "start_time": "2022-02-12T20:11:41.637Z"
   },
   {
    "duration": 35085,
    "start_time": "2022-02-12T20:11:48.150Z"
   },
   {
    "duration": 3,
    "start_time": "2022-02-12T20:12:23.448Z"
   },
   {
    "duration": 6,
    "start_time": "2022-02-12T20:12:27.640Z"
   },
   {
    "duration": 2,
    "start_time": "2022-02-12T20:12:28.125Z"
   },
   {
    "duration": 2741,
    "start_time": "2022-02-12T20:12:28.571Z"
   },
   {
    "duration": 9,
    "start_time": "2022-02-12T20:12:36.633Z"
   },
   {
    "duration": 6,
    "start_time": "2022-02-12T20:12:44.605Z"
   },
   {
    "duration": 8,
    "start_time": "2022-02-12T20:12:46.397Z"
   },
   {
    "duration": 7,
    "start_time": "2022-02-12T20:13:49.142Z"
   },
   {
    "duration": 7,
    "start_time": "2022-02-12T20:13:53.339Z"
   },
   {
    "duration": 9,
    "start_time": "2022-02-12T20:13:54.827Z"
   },
   {
    "duration": 29703,
    "start_time": "2022-02-17T10:34:16.840Z"
   },
   {
    "duration": 1861,
    "start_time": "2022-02-17T10:34:46.545Z"
   },
   {
    "duration": 1370,
    "start_time": "2022-02-17T10:34:47.039Z"
   },
   {
    "duration": 1369,
    "start_time": "2022-02-17T10:34:47.041Z"
   },
   {
    "duration": 1368,
    "start_time": "2022-02-17T10:34:47.043Z"
   },
   {
    "duration": 1364,
    "start_time": "2022-02-17T10:34:47.048Z"
   },
   {
    "duration": 1363,
    "start_time": "2022-02-17T10:34:47.050Z"
   },
   {
    "duration": 1363,
    "start_time": "2022-02-17T10:34:47.052Z"
   },
   {
    "duration": 1356,
    "start_time": "2022-02-17T10:34:47.060Z"
   },
   {
    "duration": 1396,
    "start_time": "2022-02-17T10:36:26.883Z"
   },
   {
    "duration": 1332,
    "start_time": "2022-02-17T10:36:34.677Z"
   },
   {
    "duration": 1569,
    "start_time": "2022-02-17T10:36:36.819Z"
   },
   {
    "duration": 1589,
    "start_time": "2022-02-17T10:37:06.262Z"
   },
   {
    "duration": 5378,
    "start_time": "2022-02-17T10:37:19.096Z"
   },
   {
    "duration": 25,
    "start_time": "2022-02-17T10:37:31.330Z"
   },
   {
    "duration": 12,
    "start_time": "2022-02-17T10:37:33.531Z"
   },
   {
    "duration": 33,
    "start_time": "2022-02-17T10:37:35.506Z"
   },
   {
    "duration": 4765,
    "start_time": "2022-02-17T10:37:38.344Z"
   },
   {
    "duration": 1377,
    "start_time": "2022-02-17T10:37:41.735Z"
   },
   {
    "duration": 1375,
    "start_time": "2022-02-17T10:37:41.738Z"
   },
   {
    "duration": 37,
    "start_time": "2022-02-17T10:39:39.177Z"
   },
   {
    "duration": 31,
    "start_time": "2022-02-17T10:39:41.454Z"
   },
   {
    "duration": 32,
    "start_time": "2022-02-17T10:39:42.095Z"
   },
   {
    "duration": 29,
    "start_time": "2022-02-17T10:39:42.559Z"
   },
   {
    "duration": 29,
    "start_time": "2022-02-17T10:39:42.921Z"
   },
   {
    "duration": 32,
    "start_time": "2022-02-17T10:39:43.310Z"
   },
   {
    "duration": 40,
    "start_time": "2022-02-17T10:39:43.716Z"
   },
   {
    "duration": 29,
    "start_time": "2022-02-17T10:39:49.387Z"
   },
   {
    "duration": 29,
    "start_time": "2022-02-17T10:39:49.814Z"
   },
   {
    "duration": 29,
    "start_time": "2022-02-17T10:39:50.129Z"
   },
   {
    "duration": 29,
    "start_time": "2022-02-17T10:39:50.479Z"
   },
   {
    "duration": 30,
    "start_time": "2022-02-17T10:39:50.766Z"
   },
   {
    "duration": 4921,
    "start_time": "2022-02-17T10:42:24.461Z"
   },
   {
    "duration": 3204,
    "start_time": "2022-02-17T10:42:36.051Z"
   },
   {
    "duration": 7,
    "start_time": "2022-02-17T10:42:43.432Z"
   },
   {
    "duration": 2378,
    "start_time": "2022-02-17T10:42:49.223Z"
   },
   {
    "duration": 5,
    "start_time": "2022-02-17T10:42:53.734Z"
   },
   {
    "duration": 5,
    "start_time": "2022-02-17T10:43:24.334Z"
   },
   {
    "duration": 2377,
    "start_time": "2022-02-17T10:43:46.405Z"
   },
   {
    "duration": 6,
    "start_time": "2022-02-17T10:43:50.776Z"
   },
   {
    "duration": 4685,
    "start_time": "2022-02-17T10:51:07.765Z"
   },
   {
    "duration": 1372,
    "start_time": "2022-02-17T10:51:11.081Z"
   },
   {
    "duration": 5,
    "start_time": "2022-02-17T10:51:23.718Z"
   },
   {
    "duration": 3,
    "start_time": "2022-02-17T10:51:49.018Z"
   },
   {
    "duration": 48,
    "start_time": "2022-02-17T10:51:51.118Z"
   },
   {
    "duration": 4951,
    "start_time": "2022-02-17T10:51:52.920Z"
   },
   {
    "duration": 4,
    "start_time": "2022-02-17T10:52:06.362Z"
   },
   {
    "duration": 261,
    "start_time": "2022-02-17T11:05:10.035Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
